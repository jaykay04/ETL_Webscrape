{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b99c715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "import os\n",
    "\n",
    "\n",
    "url = \"https://dev.to/latest\"\n",
    "ua = UserAgent()\n",
    "userAgent = ua.random\n",
    "headers = {\"user-agent\": userAgent}\n",
    "page = requests.get(url, headers = headers)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e024cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_box = soup.find_all(\"div\", class_ = \"crayons-story__body\")\n",
    "\n",
    "links = []\n",
    "titles = []\n",
    "time_uploaded = []\n",
    "authors = []\n",
    "tags = []\n",
    "reading_times = []\n",
    "\n",
    "for box in blog_box:\n",
    "    #links\n",
    "    if box.find(\"h2\", class_ = \"crayons-story__title\") is not None:\n",
    "        link = box.find(\"h2\", class_ = \"crayons-story__title\").a\n",
    "        link = link[\"href\"]\n",
    "        links.append(link.strip())\n",
    "    else:\n",
    "        links.append(\"None\")\n",
    "        \n",
    "    #titles\n",
    "    if box.find(\"h2\", class_ = \"crayons-story__title\") is not None:\n",
    "        title = box.find(\"h2\", class_ = \"crayons-story__title\")\n",
    "        titles.append(title.text.replace(\"\\n\", \"\").strip())\n",
    "    else:\n",
    "        titles.append(\"None\")\n",
    "        \n",
    "    #time_uploaded\n",
    "    if box.find(\"time\", attrs = {\"datetime\": True}) is not None:\n",
    "        time_upload = box.find(\"time\", attrs = {\"datetime\": True})\n",
    "        time_upload = time_upload[\"datetime\"]\n",
    "        time_uploaded.append(time_upload)\n",
    "    else:\n",
    "        time_uploaded.append(\"None\")\n",
    "        \n",
    "    #authors\n",
    "    if box.find(\"a\", class_ = \"crayons-story__secondary fw-medium m:hidden\") is not None:\n",
    "        author = box.find(\"a\", class_ = \"crayons-story__secondary fw-medium m:hidden\")\n",
    "        authors.append(author.text.replace(\"\\n\", \"\").strip())\n",
    "    else:\n",
    "        authors.append(\"None\")\n",
    "        \n",
    "    #tags\n",
    "    if box.find(\"div\", class_ = \"crayons-story__tags\") is not None:\n",
    "        tag = box.find(\"div\", class_ = \"crayons-story__tags\")\n",
    "        tags.append(tag.text.replace(\"\\n\", \" \").strip())\n",
    "    else:\n",
    "        tags.append(\"None\")\n",
    "        \n",
    "    #reading_times\n",
    "    if box.find(\"div\",class_ = \"crayons-story__save\") is not None:\n",
    "        reading_time = box.find(\"div\",class_ = \"crayons-story__save\")\n",
    "        reading_times.append(reading_time.text.replace(\"\\n\", \"\").strip())\n",
    "    else:\n",
    "        reading_times.append(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "527226a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Link\": links,\n",
    "        \"Title\": titles,\n",
    "        \"Time_Uploaded\": time_uploaded,\n",
    "        \"Author\": authors,\n",
    "        \"Tag\": tags,\n",
    "        \"Reading_Time\": reading_times\n",
    "    }\n",
    ")\n",
    "\n",
    "blog_df = blog_df[blog_df[\"Link\"] != \"None\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de13c5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://dev.to/bekahhw/taking-time-to-breathe-a-new-chapter-begins-42nn',\n",
       " 'https://dev.to/devops_fundamental/aws-fundamentals-aws-marketplace-kim',\n",
       " 'https://dev.to/mukilaperiyasamy/today-i-learned-objectthis-keyword-and-hoisting-in-reactjs-6dl',\n",
       " 'https://dev.to/devops_fundamental/azure-fundamentals-microsoftapp-51dg',\n",
       " 'https://dev.to/devops_fundamental/gcp-fundamentals-ad-exchange-buyer-api-ii-5fk9',\n",
       " 'https://dev.to/nextblockcms/we-just-launched-our-dev-docs-for-nextblock-cms-nextjs-supabase-3h10',\n",
       " 'https://dev.to/lovestaco/locking-it-down-with-redis-acls-a-devs-guide-to-secure-access-1935',\n",
       " 'https://dev.to/vaib/unlocking-the-power-of-public-cloud-essential-deployment-resources-1big',\n",
       " 'https://dev.to/ivanrochacardoso/dashboard-em-tempo-real-com-vuejs-quasar-mqtt-usando-hivemq-2d47',\n",
       " 'https://dev.to/saber9-8/your-guide-to-basic-linux-commands-day05-3ake',\n",
       " 'https://dev.to/jpraiseofficial/translating-my-javascript-project-to-typescript-lessons-surprises-and-a-few-gotchas-apc',\n",
       " 'https://dev.to/devops_fundamental/aws-fundamentals-autoscaling-plans-162o',\n",
       " 'https://dev.to/devops_fundamental/azure-fundamentals-microsoftapimanagement-1dgj',\n",
       " 'https://dev.to/fluentfuture/designing-a-better-string-utility-4k49',\n",
       " 'https://dev.to/zerohertz/code-review-deep-dive-into-vllms-architecture-and-implementation-analysis-of-openai-compatible-4cp9',\n",
       " 'https://dev.to/davinceleecode/what-is-kubernetes-4ao3',\n",
       " 'https://dev.to/techtalk/it-reminded-me-that-success-is-not-flashy-it-is-built-quietly-with-habits-and-intention-4jao',\n",
       " 'https://dev.to/vjygour/10-javascript-interview-questions-with-answers-2i3k',\n",
       " 'https://dev.to/shreya111111/ai-marketwatch-product-research-agent-for-e-commerce-by-runnerh-2lnd',\n",
       " 'https://dev.to/patentscanai/google-scholar-patent-search-key-limitations-for-ip-pros-11f0',\n",
       " 'https://dev.to/mechcloud_academy/css-nesting-and-its-potential-to-replace-css-preprocessors-like-scss-and-sass-1l74',\n",
       " 'https://dev.to/devops_fundamental/gcp-fundamentals-access-context-manager-api-2d9g',\n",
       " 'https://dev.to/devops_fundamental/aws-fundamentals-autoscaling-52o3',\n",
       " 'https://dev.to/devops_fundamental/azure-fundamentals-microsoftanalysisservices-3eid',\n",
       " 'https://dev.to/kousay_najar_c0242646d307/latest-news-in-javascript-trends-updates-and-community-insights-3426']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_df.Link.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c2843c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = []\n",
    "article_link = []\n",
    "\n",
    "def get_full_content(url2):\n",
    "    ua = UserAgent()\n",
    "    userAgent = ua.random\n",
    "    headers = {\"user-agent\": userAgent}\n",
    "    page = requests.get(url2, headers = headers)\n",
    "\n",
    "    soup2 = BeautifulSoup(page.content, \"html.parser\")\n",
    "    #print(url2)\n",
    "\n",
    "\n",
    "\n",
    "    content = soup2.find(\"div\", class_ = \"crayons-article__main\")\n",
    "\n",
    "    paragraphs = content.find_all(\"p\")\n",
    "\n",
    "    contents = []\n",
    "\n",
    "    for x in paragraphs:\n",
    "        contents.append(x.text.replace(\"\\n\", \" \"))\n",
    "\n",
    "    full_content = \" \".join(contents)\n",
    "    article.append(full_content)\n",
    "    article_link.append(url2)\n",
    "    \n",
    "for i in blog_df.Link:\n",
    "    get_full_content(i)\n",
    "\n",
    "article_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Link\": article_link,\n",
    "        \"Article_Content\": article\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf1dad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = blog_df.merge(article_df, on = \"Link\", how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc5a557a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langid in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (1.1.6)\n",
      "Requirement already satisfied: pycountry in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (24.6.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langid) (1.23.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: click in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: joblib in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from nltk) (1.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langid pycountry nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "034f482e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Download the stopwords dataset\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"vader_lexicon\")\n",
    "nltk.download(\"punkt_tab\")\n",
    "\n",
    "\n",
    "def count_words_without_stopwords(text):\n",
    "    if isinstance(text, (str, bytes)):\n",
    "        words = nltk.word_tokenize(str(text))\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "        return len(filtered_words)\n",
    "    else:\n",
    "        0\n",
    "        \n",
    "merged_df['Word_Count'] = merged_df[\"Article_Content\"].apply(count_words_without_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40f815c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(record):\n",
    "    sentiment_scores = sent.polarity_scores(record)\n",
    "    compound_score = sentiment_scores['compound']\n",
    "    \n",
    "    if compound_score >= 0.05:\n",
    "        sentiment = 'Positive'\n",
    "    elif compound_score <= -0.05:\n",
    "        sentiment = 'Negative'\n",
    "    else:\n",
    "        sentiment = 'Neutral'\n",
    "        \n",
    "    return compound_score, sentiment\n",
    "\n",
    "merged_df[['Compound_Score' ,'Sentiment']] = merged_df['Article_Content'].astype(str).apply(lambda x: pd.Series(get_sentiment(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7dda683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langid\n",
    "import pycountry\n",
    "\n",
    "def detect_language(text):\n",
    "    # Convert Nan to an empty string\n",
    "    text = str(text) if pd.notna(text) else ''\n",
    "    \n",
    "    # Use langid to detect the language\n",
    "    lang, confidence = langid.classify(text)\n",
    "    return lang\n",
    "\n",
    "merged_df['Language'] = merged_df['Article_Content'].apply(detect_language)\n",
    "merged_df['Language'] = merged_df['Language'].map(lambda code: pycountry.languages.get(alpha_2 = code).name if pycountry.languages.get(alpha_2 = code) else code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e580811a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>Title</th>\n",
       "      <th>Time_Uploaded</th>\n",
       "      <th>Author</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Reading_Time</th>\n",
       "      <th>Article_Content</th>\n",
       "      <th>Word_Count</th>\n",
       "      <th>Compound_Score</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://dev.to/bekahhw/taking-time-to-breathe-...</td>\n",
       "      <td>Taking Time to Breathe: A New Chapter Begins</td>\n",
       "      <td>2025-06-19T17:25:07Z</td>\n",
       "      <td>BekahHW</td>\n",
       "      <td>#community #career</td>\n",
       "      <td>2</td>\n",
       "      <td>As of June 1st, I'm no longer with the Linux F...</td>\n",
       "      <td>165</td>\n",
       "      <td>0.9807</td>\n",
       "      <td>Positive</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://dev.to/devops_fundamental/aws-fundamen...</td>\n",
       "      <td>AWS Fundamentals: Aws Marketplace</td>\n",
       "      <td>2025-06-19T17:18:14Z</td>\n",
       "      <td>DevOps Fundamental</td>\n",
       "      <td>#aws #cloudcomputing #devops #awsmarketplace</td>\n",
       "      <td>6</td>\n",
       "      <td>In today's fast-paced, digital world, cloud se...</td>\n",
       "      <td>311</td>\n",
       "      <td>0.9942</td>\n",
       "      <td>Positive</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://dev.to/mukilaperiyasamy/today-i-learne...</td>\n",
       "      <td>Today I learned-Object,this keyword and hoisti...</td>\n",
       "      <td>2025-06-19T17:16:33Z</td>\n",
       "      <td>P Mukila</td>\n",
       "      <td>#objectreact #hoistingreact #thiskeyword</td>\n",
       "      <td>2</td>\n",
       "      <td>1.What is an Object in React.js? In JavaScript...</td>\n",
       "      <td>88</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://dev.to/devops_fundamental/azure-fundam...</td>\n",
       "      <td>Azure Fundamentals: Microsoft.App</td>\n",
       "      <td>2025-06-19T17:14:23Z</td>\n",
       "      <td>DevOps Fundamental</td>\n",
       "      <td>#azure #microsoft #devops #microsoftapp</td>\n",
       "      <td>4</td>\n",
       "      <td>Picture this: You're a startup CTO racing to d...</td>\n",
       "      <td>275</td>\n",
       "      <td>0.9427</td>\n",
       "      <td>Positive</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://dev.to/devops_fundamental/gcp-fundamen...</td>\n",
       "      <td>GCP Fundamentals: Ad Exchange Buyer API II</td>\n",
       "      <td>2025-06-19T17:09:37Z</td>\n",
       "      <td>DevOps Fundamental</td>\n",
       "      <td>#gcp #googlecloud #devops #adexchangebuyerapiii</td>\n",
       "      <td>3</td>\n",
       "      <td>Digital advertising is a fast-paced, data-driv...</td>\n",
       "      <td>282</td>\n",
       "      <td>0.9274</td>\n",
       "      <td>Positive</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Link  \\\n",
       "0  https://dev.to/bekahhw/taking-time-to-breathe-...   \n",
       "1  https://dev.to/devops_fundamental/aws-fundamen...   \n",
       "2  https://dev.to/mukilaperiyasamy/today-i-learne...   \n",
       "3  https://dev.to/devops_fundamental/azure-fundam...   \n",
       "4  https://dev.to/devops_fundamental/gcp-fundamen...   \n",
       "\n",
       "                                               Title         Time_Uploaded  \\\n",
       "0       Taking Time to Breathe: A New Chapter Begins  2025-06-19T17:25:07Z   \n",
       "1                  AWS Fundamentals: Aws Marketplace  2025-06-19T17:18:14Z   \n",
       "2  Today I learned-Object,this keyword and hoisti...  2025-06-19T17:16:33Z   \n",
       "3                  Azure Fundamentals: Microsoft.App  2025-06-19T17:14:23Z   \n",
       "4         GCP Fundamentals: Ad Exchange Buyer API II  2025-06-19T17:09:37Z   \n",
       "\n",
       "               Author                                              Tag  \\\n",
       "0             BekahHW                               #community #career   \n",
       "1  DevOps Fundamental     #aws #cloudcomputing #devops #awsmarketplace   \n",
       "2            P Mukila         #objectreact #hoistingreact #thiskeyword   \n",
       "3  DevOps Fundamental          #azure #microsoft #devops #microsoftapp   \n",
       "4  DevOps Fundamental  #gcp #googlecloud #devops #adexchangebuyerapiii   \n",
       "\n",
       "   Reading_Time                                    Article_Content  \\\n",
       "0             2  As of June 1st, I'm no longer with the Linux F...   \n",
       "1             6  In today's fast-paced, digital world, cloud se...   \n",
       "2             2  1.What is an Object in React.js? In JavaScript...   \n",
       "3             4  Picture this: You're a startup CTO racing to d...   \n",
       "4             3  Digital advertising is a fast-paced, data-driv...   \n",
       "\n",
       "   Word_Count  Compound_Score Sentiment Language  \n",
       "0         165          0.9807  Positive  English  \n",
       "1         311          0.9942  Positive  English  \n",
       "2          88          0.0000   Neutral  English  \n",
       "3         275          0.9427  Positive  English  \n",
       "4         282          0.9274  Positive  English  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = merged_df[merged_df['Language'] == 'English'].reset_index(drop = True)\n",
    "filtered_df['Reading_Time'] = filtered_df['Reading_Time'].str.replace(' min read', '', regex=False).str.strip().astype(int)\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30d893db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2\n",
      "  Downloading psycopg2-2.9.10-cp310-cp310-win_amd64.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 136.7 kB/s eta 0:00:00\n",
      "Installing collected packages: psycopg2\n",
      "Successfully installed psycopg2-2.9.10\n"
     ]
    }
   ],
   "source": [
    "# CREATE TABLE IF NOT EXISTS articles(\n",
    "# Link TEXT,\n",
    "# Title TEXT,\n",
    "# Time_Uploaded TIMESTAMP,\n",
    "# Author TEXT,\n",
    "# Tag TEXT,\n",
    "# Reading_Time INTEGER,\n",
    "# Article_Content TEXT,\n",
    "# Word_Count INTEGER,\n",
    "# Compound_Score NUMERIC,\n",
    "# Sentiment TEXT,\n",
    "# Language TEXT\n",
    "# );\n",
    "\n",
    "!pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f861008c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "db_params = {\n",
    "    \"dbname\": \"postgres\",\n",
    "    \"user\": \"postgres.mkykuvtjidbtsasqrnfn\",\n",
    "    \"password\": \"jaykayboss\",\n",
    "    \"host\": \"aws-0-eu-west-1.pooler.supabase.com\",\n",
    "    \"port\": \"5432\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Connect to PostgreSQL\n",
    "    conn = psycopg2.connect(**db_params)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # SQL Insert Query\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO articles (Link, Title, Time_Uploaded, Author, Tag, Reading_Time, Article_Content, Word_Count, Compound_Score, Sentiment, Language)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s,%s, %s, %s, %s)\n",
    "    ON CONFLICT (Link) DO NOTHING;  -- Avoids duplicate primary key errors\n",
    "    \"\"\"\n",
    "    \n",
    "    # Insert DataFrame records one by one\n",
    "    for _, row in filtered_df.iterrows():\n",
    "        cursor.execute(insert_query, (\n",
    "            row['Link'], row['Title'], row['Time_Uploaded'],  row['Author'], row['Tag'], row['Reading_Time'],\n",
    "            row['Article_Content'],row['Word_Count'],row['Compound_Score'],row['Sentiment'],row['Language']\n",
    "        ))\n",
    "\n",
    "    # Commit and close\n",
    "    conn.commit()\n",
    "    print(\"Data inserted successfully!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "finally:\n",
    "    if conn:\n",
    "        cursor.close()\n",
    "        conn.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f15566e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
